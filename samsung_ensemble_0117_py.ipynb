{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "samsung_ensemble_0117.py",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOLdgEKrTvkgf1BnQy6QiN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoungriKIM/Using_Colab/blob/main/samsung_ensemble_0117_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEGLlROblQVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab4d47c-05a6-4a0f-bf26-b9f4e2c01272"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "# 데이터 불러오기\r\n",
        "x1_train = np.load('/content/drive/My Drive/colab_data/ensemble_data_ss.npy', allow_pickle=True)[0]\r\n",
        "x1_val = np.load('/content/drive/My Drive/colab_data/ensemble_data_ss.npy', allow_pickle=True)[1]\r\n",
        "x1_test = np.load('/content/drive/My Drive/colab_data/ensemble_data_ss.npy', allow_pickle=True)[2]\r\n",
        "x1_pred = np.load('/content/drive/My Drive/colab_data/ensemble_data_ss.npy', allow_pickle=True)[3]\r\n",
        "\r\n",
        "x2_train = np.load('/content/drive/My Drive/colab_data/ensemble_data_kodex.npy', allow_pickle=True)[0]\r\n",
        "y2_train = np.load('/content/drive/My Drive/colab_data/ensemble_data_kodex.npy', allow_pickle=True)[1]\r\n",
        "x2_val = np.load('/content/drive/My Drive/colab_data/ensemble_data_kodex.npy', allow_pickle=True)[2]\r\n",
        "y2_val = np.load('/content/drive/My Drive/colab_data/ensemble_data_kodex.npy', allow_pickle=True)[3]\r\n",
        "x2_test = np.load('/content/drive/My Drive/colab_data/ensemble_data_kodex.npy', allow_pickle=True)[4]\r\n",
        "y2_test = np.load('/content/drive/My Drive/colab_data/ensemble_data_kodex.npy', allow_pickle=True)[5]\r\n",
        "x2_pred = np.load('/content/drive/My Drive/colab_data/ensemble_data_kodex.npy', allow_pickle=True)[6]\r\n",
        "\r\n",
        "#모델 구성\r\n",
        "from tensorflow.keras.models import Sequential, Model\r\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Conv1D, Flatten, MaxPooling1D, LSTM, GRU, LeakyReLU, concatenate\r\n",
        "\r\n",
        "#모델1\r\n",
        "input1 = Input(shape = (x1_train.shape[1], x1_train.shape[2]))\r\n",
        "conv1 = Conv1D(filters = 400, kernel_size = 2, strides=1, padding = 'same', activation='relu')(input1)\r\n",
        "pool1 = MaxPooling1D(pool_size=2)(conv1)\r\n",
        "conv1 = Conv1D(400, 2, padding='same')(pool1)\r\n",
        "conv1 = Conv1D(200, 2, padding='same')(conv1)\r\n",
        "conv1 = Conv1D(200, 2, padding='same')(conv1)\r\n",
        "pool1 = MaxPooling1D(pool_size=2)(conv1)\r\n",
        "flat1 = Flatten()(pool1)\r\n",
        "dense1 = Dense(16)(flat1)\r\n",
        "dense1 = Dense(16)(dense1)\r\n",
        "dense1 = Dense(16)(dense1)\r\n",
        "dense1 = Dense(4)(dense1)\r\n",
        "dense1 = Dense(4)(dense1)\r\n",
        "\r\n",
        "#모델2\r\n",
        "input2 = Input(shape = (x2_train.shape[1], x2_train.shape[2]))\r\n",
        "conv2 = Conv1D(filters = 400, kernel_size = 2, strides=1, padding = 'same', activation='relu')(input2)\r\n",
        "pool2 = MaxPooling1D(pool_size=2)(conv2)\r\n",
        "conv2 = Conv1D(200, 2, padding='same')(pool2)\r\n",
        "flat2 = Flatten()(conv2)\r\n",
        "dense2 = Dense(32)(flat2)\r\n",
        "dense2 = Dense(32)(dense2)\r\n",
        "dense2 = Dense(16)(dense2)\r\n",
        "dense2 = Dense(16)(dense2)\r\n",
        "dense2 = Dense(8)(dense2)\r\n",
        "dense2 = Dense(4)(dense2)\r\n",
        "\r\n",
        "\r\n",
        "#모델 병합\r\n",
        "merge1 = concatenate([dense1, dense2])\r\n",
        "output1 = Dense(2)(merge1)\r\n",
        "\r\n",
        "model = Model(inputs = [input1, input2], outputs = output1)\r\n",
        "\r\n",
        "\r\n",
        "#3. 컴파일, 핏\r\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\r\n",
        "\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\r\n",
        "stop = EarlyStopping(monitor='val_loss', patience=16, mode='min')\r\n",
        "\r\n",
        "modelpath = '/content/drive/My Drive/colab_data/modelcheckpoint/ss_ensemble_{epoch:02d}-{val_loss:08f}.hdf5'\r\n",
        "check = ModelCheckpoint(filepath=modelpath, monitor='val_loss', save_best_only=True, mode='auto')\r\n",
        "\r\n",
        "# hist = model.fit(x_train, y_train, epochs=20, batch_size=4, validation_data=(x_val, y_val), verbose=1, callbacks=[stop])#, check])\r\n",
        "hist = model.fit([x1_train, x2_train], y2_train, epochs=100, batch_size=2, validation_data=([x1_val, x2_val], y2_val), verbose=2, callbacks=[stop, check])\r\n",
        "\r\n",
        "\r\n",
        "#4. 평가, 예측\r\n",
        "result = model.evaluate([x1_test, x2_test], y2_test, batch_size=2)\r\n",
        "print('mse: ', format(result[0], ','))\r\n",
        "print('mae: ', format(result[1], ','))\r\n",
        "\r\n",
        "y_pred = model.predict([x1_pred, x2_pred])\r\n",
        "print('1/18일, 19일 삼성주식 시가는: ', y_pred, '입니다.')\r\n",
        "\r\n",
        "# mse:  16,082,799.0        4\r\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "160/160 - 3s - loss: 617035136.0000 - mae: 16888.4766 - val_loss: 89930320.0000 - val_mae: 6489.3130\n",
            "Epoch 2/100\n",
            "160/160 - 1s - loss: 56898976.0000 - mae: 5526.3193 - val_loss: 71628752.0000 - val_mae: 5486.1958\n",
            "Epoch 3/100\n",
            "160/160 - 1s - loss: 45168472.0000 - mae: 4823.9399 - val_loss: 83955584.0000 - val_mae: 6450.2217\n",
            "Epoch 4/100\n",
            "160/160 - 2s - loss: 45457912.0000 - mae: 4874.6270 - val_loss: 68623480.0000 - val_mae: 5351.8784\n",
            "Epoch 5/100\n",
            "160/160 - 2s - loss: 39701128.0000 - mae: 4467.8159 - val_loss: 69836256.0000 - val_mae: 5727.2515\n",
            "Epoch 6/100\n",
            "160/160 - 1s - loss: 37156188.0000 - mae: 4463.6807 - val_loss: 60635572.0000 - val_mae: 5187.9932\n",
            "Epoch 7/100\n",
            "160/160 - 1s - loss: 33308444.0000 - mae: 4306.6616 - val_loss: 64754248.0000 - val_mae: 5314.8618\n",
            "Epoch 8/100\n",
            "160/160 - 2s - loss: 30867338.0000 - mae: 4125.6465 - val_loss: 61648724.0000 - val_mae: 5080.2896\n",
            "Epoch 9/100\n",
            "160/160 - 2s - loss: 29629098.0000 - mae: 4140.8193 - val_loss: 47824488.0000 - val_mae: 4387.5220\n",
            "Epoch 10/100\n",
            "160/160 - 2s - loss: 27680348.0000 - mae: 3995.0464 - val_loss: 44194484.0000 - val_mae: 4386.2612\n",
            "Epoch 11/100\n",
            "160/160 - 2s - loss: 20547510.0000 - mae: 3444.3418 - val_loss: 38748272.0000 - val_mae: 3867.0083\n",
            "Epoch 12/100\n",
            "160/160 - 2s - loss: 19262032.0000 - mae: 3336.2559 - val_loss: 34549392.0000 - val_mae: 3717.4243\n",
            "Epoch 13/100\n",
            "160/160 - 2s - loss: 14823243.0000 - mae: 2868.4685 - val_loss: 31539942.0000 - val_mae: 3144.6323\n",
            "Epoch 14/100\n",
            "160/160 - 2s - loss: 11559107.0000 - mae: 2506.9126 - val_loss: 30881516.0000 - val_mae: 3072.0408\n",
            "Epoch 15/100\n",
            "160/160 - 2s - loss: 9447778.0000 - mae: 2184.3511 - val_loss: 22516848.0000 - val_mae: 2209.8306\n",
            "Epoch 16/100\n",
            "160/160 - 2s - loss: 9730976.0000 - mae: 2141.7761 - val_loss: 21570778.0000 - val_mae: 2396.6487\n",
            "Epoch 17/100\n",
            "160/160 - 2s - loss: 8198408.0000 - mae: 1945.8154 - val_loss: 31620912.0000 - val_mae: 3219.8838\n",
            "Epoch 18/100\n",
            "160/160 - 2s - loss: 8409517.0000 - mae: 1941.5511 - val_loss: 19041342.0000 - val_mae: 1801.7594\n",
            "Epoch 19/100\n",
            "160/160 - 2s - loss: 6607031.0000 - mae: 1589.9226 - val_loss: 22269060.0000 - val_mae: 2099.9614\n",
            "Epoch 20/100\n",
            "160/160 - 2s - loss: 8550450.0000 - mae: 2003.9183 - val_loss: 27170474.0000 - val_mae: 2711.9390\n",
            "Epoch 21/100\n",
            "160/160 - 2s - loss: 6056697.0000 - mae: 1547.5209 - val_loss: 18304120.0000 - val_mae: 1579.0901\n",
            "Epoch 22/100\n",
            "160/160 - 2s - loss: 5869953.0000 - mae: 1534.9788 - val_loss: 20470788.0000 - val_mae: 1700.6666\n",
            "Epoch 23/100\n",
            "160/160 - 1s - loss: 5163557.5000 - mae: 1398.4319 - val_loss: 20066018.0000 - val_mae: 1625.7795\n",
            "Epoch 24/100\n",
            "160/160 - 2s - loss: 5543344.5000 - mae: 1472.0240 - val_loss: 19205702.0000 - val_mae: 1602.7175\n",
            "Epoch 25/100\n",
            "160/160 - 1s - loss: 5716184.5000 - mae: 1524.2465 - val_loss: 25505580.0000 - val_mae: 3318.6042\n",
            "Epoch 26/100\n",
            "160/160 - 2s - loss: 7468964.0000 - mae: 1922.5551 - val_loss: 20131072.0000 - val_mae: 1547.0031\n",
            "Epoch 27/100\n",
            "160/160 - 1s - loss: 4851040.0000 - mae: 1479.1102 - val_loss: 18368326.0000 - val_mae: 1652.6791\n",
            "Epoch 28/100\n",
            "160/160 - 1s - loss: 4888727.5000 - mae: 1476.1010 - val_loss: 20054116.0000 - val_mae: 1716.8844\n",
            "Epoch 29/100\n",
            "160/160 - 1s - loss: 4711318.0000 - mae: 1473.1624 - val_loss: 19195582.0000 - val_mae: 1481.0569\n",
            "Epoch 30/100\n",
            "160/160 - 1s - loss: 4309222.0000 - mae: 1403.8826 - val_loss: 22188850.0000 - val_mae: 1939.8342\n",
            "Epoch 31/100\n",
            "160/160 - 1s - loss: 4603054.5000 - mae: 1512.7272 - val_loss: 18624754.0000 - val_mae: 1585.1479\n",
            "Epoch 32/100\n",
            "160/160 - 1s - loss: 4385719.0000 - mae: 1438.2280 - val_loss: 23158320.0000 - val_mae: 2296.4688\n",
            "Epoch 33/100\n",
            "160/160 - 1s - loss: 4303396.5000 - mae: 1473.8665 - val_loss: 18186410.0000 - val_mae: 1432.1902\n",
            "Epoch 34/100\n",
            "160/160 - 1s - loss: 4822513.0000 - mae: 1605.5969 - val_loss: 18807754.0000 - val_mae: 1315.7357\n",
            "Epoch 35/100\n",
            "160/160 - 1s - loss: 3475309.2500 - mae: 1321.6211 - val_loss: 18705182.0000 - val_mae: 1691.8557\n",
            "Epoch 36/100\n",
            "160/160 - 1s - loss: 3511447.5000 - mae: 1355.1897 - val_loss: 19204786.0000 - val_mae: 1929.4264\n",
            "Epoch 37/100\n",
            "160/160 - 1s - loss: 3742598.7500 - mae: 1412.9905 - val_loss: 18873858.0000 - val_mae: 1675.1211\n",
            "Epoch 38/100\n",
            "160/160 - 1s - loss: 4438712.5000 - mae: 1589.1420 - val_loss: 20430430.0000 - val_mae: 1554.7131\n",
            "Epoch 39/100\n",
            "160/160 - 1s - loss: 3276523.5000 - mae: 1337.5720 - val_loss: 22978028.0000 - val_mae: 2149.5247\n",
            "Epoch 40/100\n",
            "160/160 - 1s - loss: 3890228.0000 - mae: 1526.1420 - val_loss: 19085384.0000 - val_mae: 1555.5901\n",
            "Epoch 41/100\n",
            "160/160 - 1s - loss: 3563354.5000 - mae: 1459.3995 - val_loss: 22086864.0000 - val_mae: 2061.0730\n",
            "Epoch 42/100\n",
            "160/160 - 1s - loss: 4053656.5000 - mae: 1539.9319 - val_loss: 18893526.0000 - val_mae: 1375.1770\n",
            "Epoch 43/100\n",
            "160/160 - 1s - loss: 3024382.0000 - mae: 1315.6282 - val_loss: 19753832.0000 - val_mae: 1499.6174\n",
            "Epoch 44/100\n",
            "160/160 - 1s - loss: 2721439.5000 - mae: 1261.0959 - val_loss: 18819342.0000 - val_mae: 1551.3705\n",
            "Epoch 45/100\n",
            "160/160 - 1s - loss: 3046980.2500 - mae: 1298.1011 - val_loss: 23882094.0000 - val_mae: 2399.8589\n",
            "Epoch 46/100\n",
            "160/160 - 1s - loss: 3335792.2500 - mae: 1370.4753 - val_loss: 18303730.0000 - val_mae: 1251.7751\n",
            "Epoch 47/100\n",
            "160/160 - 1s - loss: 2752185.7500 - mae: 1294.9203 - val_loss: 18579676.0000 - val_mae: 1645.4426\n",
            "Epoch 48/100\n",
            "160/160 - 1s - loss: 3034633.2500 - mae: 1328.8815 - val_loss: 19574890.0000 - val_mae: 1423.2722\n",
            "Epoch 49/100\n",
            "160/160 - 1s - loss: 2806888.0000 - mae: 1271.4796 - val_loss: 18571092.0000 - val_mae: 1203.7408\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 1327130.2500 - mae: 852.3250\n",
            "mse:  1,327,130.25\n",
            "mae:  852.3250122070312\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5938b0b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/18일, 19일 삼성주식 시가는:  [[89601.77 89732.09]] 입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}