{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras41_cnn1_boston_re.py",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+U905OZlLWimgGhQ5zVrc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoungriKIM/Using_Colab/blob/main/keras41_cnn1_boston_re_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6uCv3fI0ZXi",
        "outputId": "02a9062c-267c-44a6-a7d0-19929710bf51"
      },
      "source": [
        "# CNN으로 구성하시오/ 2차원을 4차원으로 늘려서 하시오.\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "#1. 데이터\r\n",
        "from sklearn.datasets import load_boston\r\n",
        "dataset = load_boston()\r\n",
        "x = dataset.data\r\n",
        "y = dataset.target\r\n",
        "\r\n",
        "# print(x.shape, y.shape)     #(506, 13) (506,)\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, shuffle=True, random_state=311)\r\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.8, shuffle=True, random_state=311)\r\n",
        "\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scaler = MinMaxScaler()\r\n",
        "scaler.fit(x_train)\r\n",
        "x_train = scaler.transform(x_train)\r\n",
        "x_val = scaler.transform(x_val)\r\n",
        "x_test = scaler.transform(x_test)\r\n",
        "\r\n",
        "# print(x_train.shape)        #(323, 13)\r\n",
        "# print(x_val.shape)          #(81, 13)\r\n",
        "# print(x_test.shape)         #(102, 13)\r\n",
        "\r\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1],1 ,1)\r\n",
        "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1],1 ,1)\r\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1],1 ,1)\r\n",
        "\r\n",
        "# print(x_train.shape)        #(323, 13, 1, 1)\r\n",
        "# print(x_val.shape)          #(81, 13, 1, 1)\r\n",
        "# print(x_test.shape)         #(102, 13, 1, 1)\r\n",
        "\r\n",
        "#2. 모델 구성\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, Input\r\n",
        "\r\n",
        "input1 = Input(shape=(13,1,1))\r\n",
        "conv1 = Conv2D(filters=78, kernel_size=(2,1), strides=1, padding='same', activation='relu')(input1)\r\n",
        "drop1 = Dropout(0.2)(conv1)\r\n",
        "conv1 = Conv2D(39, (2,1))(drop1)\r\n",
        "flat1 = Flatten()(conv1)\r\n",
        "dense1 = Dense(39)(flat1)\r\n",
        "dense1 = Dense(13)(dense1)\r\n",
        "output1 = Dense(1)(dense1)\r\n",
        "model = Model(inputs = input1, outputs = output1)\r\n",
        "\r\n",
        "# model.summary()\r\n",
        "\r\n",
        "#3. 컴파일, 훈련\r\n",
        "model.compile(loss='mse', optimizer='adam')\r\n",
        "\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "stop = EarlyStopping(monitor='loss', patience=20, mode='min')\r\n",
        "\r\n",
        "model.fit(x_train, y_train, epochs=1000, batch_size=13, validation_data=(x_val, y_val), verbose=1, callbacks=[stop])\r\n",
        "\r\n",
        "#4. 평가, 예측\r\n",
        "loss = model.evaluate(x_test, y_test, batch_size=13)\r\n",
        "print('loss: ', loss)\r\n",
        "\r\n",
        "y_pred = model.predict(x_test[:5])\r\n",
        "print('y_pred: \\n', y_pred)\r\n",
        "print('y_test: ', y_test[:5])\r\n",
        "\r\n",
        "# 41-1 boston CNN\r\n",
        "# loss:  22.685556411743164\r\n",
        "# y_pred: \r\n",
        "#  [[24.685066]\r\n",
        "#  [14.187754]\r\n",
        "#  [20.230017]\r\n",
        "#  [26.658447]\r\n",
        "#  [18.59134 ]]\r\n",
        "# y_test:  [19.1 17.2 17.8 23.4 14.6]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "25/25 [==============================] - 1s 9ms/step - loss: 477.0400 - val_loss: 164.5882\n",
            "Epoch 2/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 168.7343 - val_loss: 115.1425\n",
            "Epoch 3/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 117.0461 - val_loss: 85.5871\n",
            "Epoch 4/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 66.3471 - val_loss: 64.1046\n",
            "Epoch 5/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 48.6286 - val_loss: 58.4440\n",
            "Epoch 6/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 47.7735 - val_loss: 55.7906\n",
            "Epoch 7/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 42.3755 - val_loss: 51.9999\n",
            "Epoch 8/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 50.6835 - val_loss: 48.6986\n",
            "Epoch 9/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 37.7324 - val_loss: 44.5027\n",
            "Epoch 10/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 31.0661 - val_loss: 46.9508\n",
            "Epoch 11/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 36.3278 - val_loss: 38.3503\n",
            "Epoch 12/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 33.1247 - val_loss: 35.4724\n",
            "Epoch 13/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 33.2839 - val_loss: 33.4021\n",
            "Epoch 14/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 29.0098 - val_loss: 31.4759\n",
            "Epoch 15/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 47.0537 - val_loss: 29.6819\n",
            "Epoch 16/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 25.3670 - val_loss: 28.3709\n",
            "Epoch 17/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 22.7257 - val_loss: 28.5028\n",
            "Epoch 18/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 27.1125 - val_loss: 25.6629\n",
            "Epoch 19/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 22.2330 - val_loss: 27.2024\n",
            "Epoch 20/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 29.1782 - val_loss: 23.9033\n",
            "Epoch 21/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 31.6667 - val_loss: 25.8570\n",
            "Epoch 22/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 29.4231 - val_loss: 29.6628\n",
            "Epoch 23/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 23.4956 - val_loss: 24.7336\n",
            "Epoch 24/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 31.4950 - val_loss: 25.7438\n",
            "Epoch 25/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 30.2598 - val_loss: 22.9535\n",
            "Epoch 26/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 24.3582 - val_loss: 22.6607\n",
            "Epoch 27/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 24.9353 - val_loss: 20.4172\n",
            "Epoch 28/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 27.7004 - val_loss: 19.5759\n",
            "Epoch 29/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 27.9703 - val_loss: 19.9200\n",
            "Epoch 30/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 18.1037 - val_loss: 19.1746\n",
            "Epoch 31/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 25.4313 - val_loss: 19.9899\n",
            "Epoch 32/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 19.8893 - val_loss: 18.5916\n",
            "Epoch 33/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 33.3883 - val_loss: 27.0175\n",
            "Epoch 34/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 22.4777 - val_loss: 19.5390\n",
            "Epoch 35/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 22.1963 - val_loss: 19.0448\n",
            "Epoch 36/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 26.5156 - val_loss: 20.5128\n",
            "Epoch 37/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 31.3912 - val_loss: 19.8729\n",
            "Epoch 38/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 25.0637 - val_loss: 20.1140\n",
            "Epoch 39/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 20.0223 - val_loss: 18.5106\n",
            "Epoch 40/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 16.6811 - val_loss: 19.5979\n",
            "Epoch 41/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 21.1827 - val_loss: 18.6400\n",
            "Epoch 42/1000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 19.8934 - val_loss: 19.7235\n",
            "Epoch 43/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 23.3430 - val_loss: 17.7946\n",
            "Epoch 44/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 33.7583 - val_loss: 18.2316\n",
            "Epoch 45/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 20.3293 - val_loss: 18.2901\n",
            "Epoch 46/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 23.6710 - val_loss: 19.0134\n",
            "Epoch 47/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 17.7930 - val_loss: 19.3535\n",
            "Epoch 48/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 29.2812 - val_loss: 20.7219\n",
            "Epoch 49/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 20.3776 - val_loss: 18.2470\n",
            "Epoch 50/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 28.4763 - val_loss: 18.4444\n",
            "Epoch 51/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 22.2698 - val_loss: 18.3242\n",
            "Epoch 52/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 28.8381 - val_loss: 21.2490\n",
            "Epoch 53/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 22.7319 - val_loss: 19.1855\n",
            "Epoch 54/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 21.0385 - val_loss: 17.2855\n",
            "Epoch 55/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 20.3809 - val_loss: 18.5836\n",
            "Epoch 56/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 20.1434 - val_loss: 18.3540\n",
            "Epoch 57/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 19.2572 - val_loss: 18.4794\n",
            "Epoch 58/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 18.5920 - val_loss: 17.6160\n",
            "Epoch 59/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 19.4278 - val_loss: 22.5332\n",
            "Epoch 60/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 22.7593 - val_loss: 17.7211\n",
            "Epoch 61/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 19.7815 - val_loss: 16.9478\n",
            "Epoch 62/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 20.1927 - val_loss: 18.4338\n",
            "Epoch 63/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 27.5773 - val_loss: 17.5703\n",
            "Epoch 64/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 18.7681 - val_loss: 17.7570\n",
            "Epoch 65/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 17.2189 - val_loss: 18.9456\n",
            "Epoch 66/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 22.4148 - val_loss: 17.4729\n",
            "Epoch 67/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 21.9985 - val_loss: 22.5839\n",
            "Epoch 68/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 19.8779 - val_loss: 19.7255\n",
            "Epoch 69/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 26.0261 - val_loss: 21.9975\n",
            "Epoch 70/1000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 19.0324 - val_loss: 24.1845\n",
            "Epoch 71/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 18.6971 - val_loss: 16.8639\n",
            "Epoch 72/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 20.9344 - val_loss: 20.3114\n",
            "Epoch 73/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 19.7002 - val_loss: 16.6831\n",
            "Epoch 74/1000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 23.0853 - val_loss: 17.6073\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 22.6856\n",
            "loss:  22.685556411743164\n",
            "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faa3cb6c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "y_pred: \n",
            " [[24.685066]\n",
            " [14.187754]\n",
            " [20.230017]\n",
            " [26.658447]\n",
            " [18.59134 ]]\n",
            "y_test:  [19.1 17.2 17.8 23.4 14.6]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}