{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras41_cnn2_diabetes_re.py",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPTqbUDkMXnz77nIm5tOecP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoungriKIM/Using_Colab/blob/main/keras41_cnn2_diabetes_re_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI_ZbXw_-aOT",
        "outputId": "0fde8d30-ed99-405b-d878-63055dbff8ff"
      },
      "source": [
        "# CNN으로 구성하시오/ 2차원을 4차원으로 늘려서 하시오.\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from sklearn.datasets import load_diabetes #당뇨병 수준\r\n",
        "\r\n",
        "#데이터 불러오고 , 이건 사이킷런의 데이터 불러오는 방법\r\n",
        "dataset = load_diabetes()\r\n",
        "x = dataset.data\r\n",
        "y = dataset.target\r\n",
        "\r\n",
        "# print(x.shape, y.shape) #(442, 10) (442,)\r\n",
        "\r\n",
        "#트레인 테스트 분리\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, shuffle=True, random_state=66)\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size = 0.8, shuffle=True, random_state=66)\r\n",
        "\r\n",
        "#데이터 전처리 (MinMaxScaler를 이용해서 , 기준은 x_train으로)\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scaler = MinMaxScaler()\r\n",
        "scaler.fit(x_train)\r\n",
        "x_train = scaler.transform(x_train)\r\n",
        "x_test = scaler.transform(x_test)\r\n",
        "x_val = scaler.transform(x_val)\r\n",
        "\r\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1],1 ,1)\r\n",
        "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1],1 ,1)\r\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1],1 ,1)\r\n",
        "\r\n",
        "print(x_train.shape)        #(282, 10, 1, 1)\r\n",
        "print(x_val.shape)          #(71, 10, 1, 1)\r\n",
        "print(x_test.shape)         #(89, 10, 1, 1)\r\n",
        "\r\n",
        "#모델 구성\r\n",
        "from tensorflow.keras.models import Model, Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Conv2D, Flatten\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(filters = 160, kernel_size=(2,1), strides=1, padding='same', input_shape=(10,1,1)))\r\n",
        "model.add(Dropout(0.2)) #이번에 붙인 부분\r\n",
        "model.add(Conv2D(160, (2,1)))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(120))\r\n",
        "model.add(Dense(80))\r\n",
        "model.add(Dense(80))\r\n",
        "model.add(Dense(1))\r\n",
        "\r\n",
        "# model.summary()\r\n",
        "\r\n",
        "#컴파일, 훈련 (Earlystopping 적용)\r\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\r\n",
        "\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=20, mode='min')\r\n",
        "model.fit(x_train, y_train, epochs=1000, batch_size=10, validation_data=(x_val, y_val), verbose=1, callbacks=[early_stopping])\r\n",
        "\r\n",
        "#평가, 예측\r\n",
        "loss, mae = model.evaluate(x_test, y_test, batch_size=1)\r\n",
        "print('loss, mae: ', loss, mae)\r\n",
        "\r\n",
        "y_predict = model.predict(x_test)\r\n",
        "\r\n",
        "#RMSE와 R2 구하기\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "def RMSE(y_test, y_predict):\r\n",
        "      return np.sqrt(mean_squared_error(y_test, y_predict))\r\n",
        "print('RMSE: ', RMSE(y_test, y_predict))\r\n",
        "\r\n",
        "from sklearn.metrics import r2_score\r\n",
        "R2 = r2_score(y_test, y_predict)\r\n",
        "print('R2: ', R2)\r\n",
        " \r\n",
        "# 6파일 19-6 diabetes DNN\r\n",
        "# loss, mae:  3121.9990234375 46.306800842285156\r\n",
        "# RMSE:  55.87484721026777\r\n",
        "# R2:  0.5189554519135346\r\n",
        "\r\n",
        "# 41-2 diabetes CNN\r\n",
        "# loss, mae:  3281.125 46.30169677734375\r\n",
        "# RMSE:  57.28110470742899\r\n",
        "# R2:  0.4944368979521947"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(282, 10, 1, 1)\n",
            "(71, 10, 1, 1)\n",
            "(89, 10, 1, 1)\n",
            "Epoch 1/1000\n",
            "29/29 [==============================] - 1s 11ms/step - loss: 22438.8217 - mae: 124.8788 - val_loss: 3827.6731 - val_mae: 50.2816\n",
            "Epoch 2/1000\n",
            "29/29 [==============================] - 0s 12ms/step - loss: 5094.8774 - mae: 60.4263 - val_loss: 3512.5737 - val_mae: 49.5111\n",
            "Epoch 3/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3978.3266 - mae: 52.3063 - val_loss: 2814.1948 - val_mae: 44.2590\n",
            "Epoch 4/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3942.2851 - mae: 51.7949 - val_loss: 2442.8433 - val_mae: 40.2265\n",
            "Epoch 5/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3251.5578 - mae: 47.1274 - val_loss: 2304.8511 - val_mae: 38.1334\n",
            "Epoch 6/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3540.9240 - mae: 48.2179 - val_loss: 2676.7356 - val_mae: 42.0272\n",
            "Epoch 7/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3193.8735 - mae: 47.2705 - val_loss: 2282.0500 - val_mae: 37.7142\n",
            "Epoch 8/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3316.7658 - mae: 47.4219 - val_loss: 2218.2708 - val_mae: 37.5520\n",
            "Epoch 9/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3399.2868 - mae: 46.2902 - val_loss: 2247.0972 - val_mae: 37.6773\n",
            "Epoch 10/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3213.5428 - mae: 45.7570 - val_loss: 2223.1306 - val_mae: 37.8973\n",
            "Epoch 11/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3425.5188 - mae: 47.3150 - val_loss: 2376.2839 - val_mae: 38.2146\n",
            "Epoch 12/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3309.1873 - mae: 46.7130 - val_loss: 2216.7212 - val_mae: 37.5909\n",
            "Epoch 13/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 2747.7205 - mae: 42.6299 - val_loss: 2197.4585 - val_mae: 37.7327\n",
            "Epoch 14/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3631.1640 - mae: 50.5209 - val_loss: 2450.1279 - val_mae: 38.0362\n",
            "Epoch 15/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3465.5362 - mae: 47.2931 - val_loss: 2641.5190 - val_mae: 39.4682\n",
            "Epoch 16/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3381.4053 - mae: 47.6705 - val_loss: 2272.5237 - val_mae: 37.7277\n",
            "Epoch 17/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 2916.2216 - mae: 43.6549 - val_loss: 3342.6870 - val_mae: 45.0308\n",
            "Epoch 18/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3894.2380 - mae: 50.5072 - val_loss: 2694.8843 - val_mae: 39.6820\n",
            "Epoch 19/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3016.4815 - mae: 45.1490 - val_loss: 2258.8979 - val_mae: 38.3373\n",
            "Epoch 20/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3162.2442 - mae: 45.1634 - val_loss: 2561.8425 - val_mae: 41.3392\n",
            "Epoch 21/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3172.6996 - mae: 44.5609 - val_loss: 2317.6194 - val_mae: 38.8278\n",
            "Epoch 22/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 2962.4432 - mae: 43.1005 - val_loss: 2548.4758 - val_mae: 41.2871\n",
            "Epoch 23/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3313.5350 - mae: 45.5522 - val_loss: 2436.6130 - val_mae: 38.4044\n",
            "Epoch 24/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3305.6280 - mae: 45.5263 - val_loss: 2560.1362 - val_mae: 39.0733\n",
            "Epoch 25/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3355.5426 - mae: 46.2799 - val_loss: 2194.5361 - val_mae: 37.7032\n",
            "Epoch 26/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3269.1772 - mae: 45.9888 - val_loss: 2259.0725 - val_mae: 37.6295\n",
            "Epoch 27/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3610.8182 - mae: 48.4262 - val_loss: 3104.3315 - val_mae: 45.2249\n",
            "Epoch 28/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3600.0597 - mae: 48.3877 - val_loss: 2237.3936 - val_mae: 37.9131\n",
            "Epoch 29/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3097.4167 - mae: 44.8542 - val_loss: 2440.8203 - val_mae: 40.0040\n",
            "Epoch 30/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3358.5972 - mae: 47.0164 - val_loss: 2297.4707 - val_mae: 37.6039\n",
            "Epoch 31/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 2955.7004 - mae: 44.6155 - val_loss: 2262.3713 - val_mae: 38.3448\n",
            "Epoch 32/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 2909.6264 - mae: 42.8281 - val_loss: 2850.7659 - val_mae: 40.6900\n",
            "Epoch 33/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3577.5915 - mae: 48.1044 - val_loss: 2304.6638 - val_mae: 38.9676\n",
            "Epoch 34/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3269.2191 - mae: 46.3121 - val_loss: 2201.3145 - val_mae: 37.5489\n",
            "Epoch 35/1000\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 3050.9536 - mae: 45.1729 - val_loss: 2176.4807 - val_mae: 37.4175\n",
            "Epoch 36/1000\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 3080.8776 - mae: 43.9712 - val_loss: 2217.2227 - val_mae: 37.6668\n",
            "89/89 [==============================] - 0s 2ms/step - loss: 3281.1250 - mae: 46.3017\n",
            "loss, mae:  3281.125 46.30169677734375\n",
            "RMSE:  57.28110470742899\n",
            "R2:  0.4944368979521947\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}